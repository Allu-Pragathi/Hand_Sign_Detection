âœ‹ Hand Gesture Recognition System
---

A real-time hand gesture recognition system powered by OpenCV, cvzone, and TensorFlow.

This project captures hand gestures through your webcam and classifies them into predefined categories (like A, B, C).

ğŸŒŸ Features
---

ğŸ–ï¸ Real-time hand detection using cvzone.HandTrackingModule

âœ‚ï¸ Automatic preprocessing (cropping, resizing, white background adjustment)

ğŸ” CNN-based classification with DepthwiseConv2D

ğŸ“¸ Built-in data collection for training your own custom gestures

ğŸ§  Customizable labels (A, B, C, etc.) â€“ retrain easily with your own data

ğŸ›  Tech Stack
---
Component	Library / Tool

Hand Detection	cvzone.HandTrackingModule

Model Framework	TensorFlow, Keras


Image Processing	OpenCV, NumPy
Classifier	cvzone.ClassificationModule
IDE (Optional)	VS Code, Jupyter

ğŸ“‚ Folder Structure
---
```bash

Hand-Gesture-Recognition/
â”œâ”€â”€ Data/
â”œâ”€â”€ Model/
â”‚   â”œâ”€â”€ keras_model.h5
â”‚   â””â”€â”€ labels.txt
â”œâ”€â”€ dataCollection.py
â”œâ”€â”€ test.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
ğŸ”§ Setup Instructions (Local)
--
Clone the repository
```bash
git clone https://github.com/your-username/Hand-Gesture-Recognition.git
cd Hand-Gesture-Recognition
```
Create a virtual environment
---
```bash
python -m venv venv
```
Activate the environment
---
Windows:
```bash
venv\Scripts\activate
```
Linux/Mac:
```bash
source venv/bin/activate
```
Install dependencies
---
```bash
pip install -r requirements.txt
```
ğŸ“¸ Collect Your Own Gesture Data
---
Run the data collection script:
```bash
python dataCollection.py
```
Your webcam will open.

Show a gesture to the camera.

Press s to save a cropped + resized image into the Data/ folder.

ğŸ–¥ï¸ Run the Gesture Recognition App
---
Once youâ€™ve collected data and trained the model:
```bash
python test.py
```
This will:
âœ… Open webcam

âœ… Detect your hand

âœ… Predict gestures in real-time

ğŸ§  Model Details
---

Model File: Model/keras_model.h5

Labels File: Model/labels.txt

Example Labels
labels = ["A", "B", "C"]


Add your own gestures, retrain the model, and update labels.txt.

âœ… Best Practices
---

Keep large datasets & trained models in external storage (not in GitHub repo).

Use a .gitignore to exclude unnecessary files (.venv/, __pycache__/, *.h5, etc.).

Separate training scripts if you plan to experiment with different architectures.

ğŸš€ Future Improvements
---

Extend to full ASL Alphabet recognition.

Deploy as a mobile app with TensorFlow Lite.

Add support for gesture-controlled applications (games, IoT, smart devices).

ğŸ‘©â€ğŸ’» Author
---

ğŸ“§allupragathi@gmail.com
